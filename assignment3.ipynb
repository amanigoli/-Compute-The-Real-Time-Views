{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_counter_DF = spark.read.csv('/home/amani/per-vehicle-records-2019-10-31.csv',inferSchema = True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vehicle_counter_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4389299"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_counter_DF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_counter_DF.registerTempTable(\"vehicle_counter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(time, rdd):\n",
    "    try:\n",
    "        df = spark.createDataFrame(rdd.map(\\\n",
    "        lambda row: Row(time=time, package=row[0], count=row[1])))\n",
    "        df.write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "        .options(table=\"question1\", keyspace=\"streaming\")\\\n",
    "        .save(mode=\"append\")\n",
    "    except:pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save3(time, rdd):\n",
    "    try:\n",
    "        df = spark.createDataFrame(rdd.map(\\\n",
    "        lambda row: Row(time=time, word=row[0], count=row[1])))\n",
    "        df.write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "        .options(table=\"question3\", keyspace=\"streaming\")\\\n",
    "        .save(mode=\"append\")\n",
    "    except:pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save4(time, rdd):\n",
    "    try:\n",
    "        df = spark.createDataFrame(rdd.map(\\\n",
    "        lambda row: Row(time=time, word=row[0], count=row[1])))\n",
    "        df.write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "        .options(table=\"question4\", keyspace=\"streaming\")\\\n",
    "        .save(mode=\"append\")\n",
    "    except:pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|vehiclecount|class|\n",
      "+------------+-----+\n",
      "|     3472965|    2|\n",
      "|      498505|    3|\n",
      "|      216978|    6|\n",
      "|      135202|    5|\n",
      "|       29347|    4|\n",
      "|       21224|    7|\n",
      "|       14682|    1|\n",
      "|         396|    0|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Show total number of counts (on each site) by vehicle class.\n",
    "\n",
    "result1=spark.sql(\"SELECT  count(class) as vehiclecount , class  from vehicle_counter  group by class order by count(class) desc \")\n",
    "result1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|class|       avg(speed)|\n",
      "+-----+-----------------+\n",
      "|    1|75.41983381010762|\n",
      "|    6|81.93572758528522|\n",
      "|    3|90.35929148153001|\n",
      "|    5|80.11806925933027|\n",
      "|    4| 79.0626980611306|\n",
      "|    7|  80.509602336977|\n",
      "|    2|87.99111496948547|\n",
      "|    0|81.18964646464646|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2. Compute the average speed (on each site) by vehicle class.\n",
    "\n",
    "result2 = vehicle_counter_DF.groupBy(\"class\")\n",
    "result2.agg({'speed':'avg'}).show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|cosit|cositcount|\n",
      "+-----+----------+\n",
      "| 1508|     98292|\n",
      "| 1502|     89498|\n",
      "| 1503|     86195|\n",
      "+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3. Find the top 3 busiest counter sites in Ireland.\n",
    "result3=spark.sql(\"SELECT cosit ,count(cosit) as cositcount from vehicle_counter group by cosit order by count(cosit) desc limit 3\")\n",
    "result3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|HGVcount|cosit|\n",
      "+--------+-----+\n",
      "|   12031|  997|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4. Find total number of counts for HGVs.\n",
    "\n",
    "result4=spark.sql(\"SELECT  count(cosit) as HGVcount, cosit  from vehicle_counter  where classname in ('HGV_ART','HGV_RIG') group by cosit order by count(cosit) desc limit 1 \") \n",
    "result4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ssc.textFileStream(\"file:///home/amani/streaming/\")\n",
    "records = lines.map(lambda line: line.split(\",\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = records.map(lambda x: ((x[0],x[14],1))\n",
    "result1 = result1.reduceByKey(lambda a,b : a+b)\n",
    "result1.foreachRDD(save)\n",
    "result1.pprint()\n",
    "ssc.start()\n",
    "time.sleep(300)\n",
    "ssc.stop(stopSparkContext=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
